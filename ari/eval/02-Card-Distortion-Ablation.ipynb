{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "495e5169",
   "metadata": {},
   "source": [
    "# Experiment 02: Ablation Study for Cardinality Distortion\n",
    "\n",
    "Process this notebook like so to generate the PDF output:\n",
    "\n",
    "```bash\n",
    "jupyter execute --inplace 01-Cardinality-Distortion.ipynb\n",
    "jupyter nbconvert --to pdf 01-Cardinality-Distortion.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ee2196",
   "metadata": {},
   "source": [
    "# Internals\n",
    "\n",
    "The cells in this section can be ignored in the PDF output. They perform the technical aspects of the data analysis.\n",
    "This includes generating a full version of the distortion plots (Figure 5 in the original paper) and selecting the best\n",
    "replacement queries.\n",
    "The plots for all queries and both cost models is exported to the `results/eval/2-distortion-ablation` directory.\n",
    "\n",
    "Please take a look at the following sections to see the actual outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84da16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections.abc import Iterable\n",
    "from typing import Literal, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import figure\n",
    "\n",
    "from postbound.experiments import workloads\n",
    "from postbound.db import postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6fa333",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_base = Path(\"/ari/results/experiment-02-distortion-ablation\")\n",
    "output_dir = Path(\"/ari/results/eval/experiment-02-distortion-ablation/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "workloads.workloads_base_dir = \"/ari/postbound/workloads\"\n",
    "plt.rcParams[\"figure.figsize\"] = (7, 6)\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42\n",
    "plt.rcParams[\"ps.fonttype\"] = 42\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef3c5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "stages = {\n",
    "    1: \"minimal\",\n",
    "    2: \"textbook\",\n",
    "    3: \"textbook-opt\",\n",
    "    4: \"intermediates\",\n",
    "    5: \"parallel\",\n",
    "}\n",
    "\n",
    "\n",
    "def load_pg_explain(raw_explain: str) -> Optional[postgres.PostgresExplainPlan]:\n",
    "    plan_json = json.loads(raw_explain)\n",
    "    if not plan_json:\n",
    "        return None\n",
    "    return postgres.PostgresExplainPlan(plan_json)\n",
    "\n",
    "\n",
    "def load_results(workload: workloads.Workload) -> Optional[pd.DataFrame]:\n",
    "    e2e_df = pd.DataFrame()\n",
    "\n",
    "    data_files = itertools.product(stages.keys(), (\"vanilla\", \"cout\"))\n",
    "    for stage, cost_model in data_files:\n",
    "        data_file = (\n",
    "            results_base\n",
    "            / workload.name\n",
    "            / f\"{workload.name}-distortion-{cost_model}-cost-stage-{stage}.csv\"\n",
    "        )\n",
    "        if not data_file.exists():\n",
    "            continue\n",
    "\n",
    "        distortion_df = pd.read_csv(\n",
    "            data_file, converters={\"query_plan\": load_pg_explain}\n",
    "        )\n",
    "        distortion_df[\"label\"] = pd.Categorical(\n",
    "            distortion_df[\"label\"], categories=workload.labels(), ordered=True\n",
    "        )\n",
    "        distortion_df[\"stage\"] = pd.Categorical(\n",
    "            distortion_df[\"stage\"].map(stages), categories=stages.values(), ordered=True\n",
    "        )\n",
    "        distortion_df[\"plan_hash\"] = distortion_df[\"query_plan\"].map(hash)\n",
    "        distortion_df[\"cost_model\"] = cost_model\n",
    "\n",
    "        e2e_df = pd.concat([e2e_df, distortion_df], ignore_index=True)\n",
    "\n",
    "    if len(e2e_df) == 0:\n",
    "        return None\n",
    "\n",
    "    return e2e_df\n",
    "\n",
    "\n",
    "def count_plan_changes(plans: pd.Series) -> int:\n",
    "    change_indicators = plans != plans.shift(-1)\n",
    "    return change_indicators.sum() - 1\n",
    "\n",
    "\n",
    "def count_jump_backs(plans: pd.Series) -> int:\n",
    "    jumps = 0\n",
    "    prev_plan = plans.iloc[0]\n",
    "    seen_plans = {prev_plan}\n",
    "    for plan in plans.iloc[1:]:\n",
    "        if plan == prev_plan:\n",
    "            continue\n",
    "\n",
    "        if plan in seen_plans:\n",
    "            jumps += 1\n",
    "        seen_plans.add(plan)\n",
    "        prev_plan = plan\n",
    "    return jumps\n",
    "\n",
    "\n",
    "def make_changes_df(df: pd.DataFrame | None) -> Optional[pd.DataFrame]:\n",
    "    if df is None:\n",
    "        return None\n",
    "\n",
    "    changes_df = (\n",
    "        df.groupby([\"cost_model\", \"label\", \"stage\"], as_index=False, observed=True)\n",
    "        .agg(\n",
    "            plan_changes=pd.NamedAgg(column=\"plan_hash\", aggfunc=count_plan_changes),\n",
    "            jump_backs=pd.NamedAgg(column=\"plan_hash\", aggfunc=count_jump_backs),\n",
    "        )\n",
    "        .sort_values(by=[\"cost_model\", \"label\", \"stage\"])\n",
    "    )\n",
    "    changes_df[\"plot_label\"] = changes_df.apply(\n",
    "        lambda row: f\"{row['plan_changes']} ({row['jump_backs']})\", axis=1\n",
    "    )\n",
    "\n",
    "    return changes_df\n",
    "\n",
    "\n",
    "def make_evolution_plot(\n",
    "    df: pd.DataFrame | None,\n",
    "    *,\n",
    "    workload: str,\n",
    "    cost_model: Literal[\"vanilla\", \"cout\"],\n",
    "    export: bool,\n",
    "    queries: Optional[Iterable[str]] = None,\n",
    ") -> Optional[figure.Figure]:\n",
    "    if df is None:\n",
    "        return None\n",
    "\n",
    "    df = df.copy()\n",
    "    vmin, vmax = 0, df[\"plan_changes\"].max()\n",
    "    cmap = sns.color_palette(\"Blues\", 12, as_cmap=True)\n",
    "\n",
    "    stages_pretty = {\n",
    "        \"minimal\": \"SeqScan\\nNestLoopJ\\n(minimal)\",\n",
    "        \"textbook\": \"+\\nIdxScan\\nMergeJ.\\nHashJ.\",\n",
    "        \"textbook-opt\": \"+\\nIdxOnlyS.\\nBitmapS.\",\n",
    "        \"intermediates\": \"+\\nMemoize\\nMaterial\",\n",
    "        \"parallel\": \"+\\nParallel.\\n(full)\",\n",
    "    }\n",
    "\n",
    "    df[\"stage_pretty\"] = pd.Categorical(\n",
    "        df[\"stage\"].map(stages_pretty), categories=stages_pretty.values(), ordered=True\n",
    "    )\n",
    "\n",
    "    data_matrix = df.pivot(index=\"label\", columns=\"stage_pretty\", values=\"plan_changes\")\n",
    "    annot_matrix = df.pivot(index=\"label\", columns=\"stage_pretty\", values=\"plot_label\")\n",
    "\n",
    "    if queries:\n",
    "        data_matrix = data_matrix.loc[queries]\n",
    "        annot_matrix = annot_matrix.loc[queries]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    g = sns.heatmap(\n",
    "        data_matrix,\n",
    "        annot=annot_matrix,\n",
    "        fmt=\"\",\n",
    "        cmap=cmap,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        linewidth=1,\n",
    "        cbar=False,\n",
    "        annot_kws={\"size\": 18, \"fontweight\": \"normal\"},\n",
    "        ax=ax,\n",
    "    )\n",
    "    g.set(xlabel=\"Available physical operators\", ylabel=\"Query\")\n",
    "    g.tick_params(axis=\"both\", which=\"major\", labelsize=16)\n",
    "\n",
    "    for i in range(len(df)):\n",
    "        ax.axhline(i, color=\"white\", lw=7.5)\n",
    "\n",
    "    if export:\n",
    "        out_file = (\n",
    "            output_dir / f\"{workload.lower()}-distortion-ablation-{cost_model}.pdf\"\n",
    "        )\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(out_file)\n",
    "\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "\n",
    "def select_replacement_queries(\n",
    "    df: pd.DataFrame | None, *, workload: str\n",
    ") -> Optional[figure.Figure]:\n",
    "    if df is None:\n",
    "        return None\n",
    "\n",
    "    target_queries: list[str] = []\n",
    "    df = df.query(\"cost_model == 'cout'\")\n",
    "\n",
    "    # determine the query with the most plan changes at the minimal stage\n",
    "    df_stage1 = df.query(\"stage == 'minimal'\")\n",
    "    target_label: str = df_stage1.loc[df_stage1[\"plan_changes\"].argmax()][\"label\"]\n",
    "    target_queries.append(target_label)\n",
    "\n",
    "    # determine the query with the most jump backs at the minimal stage\n",
    "    target_label = df_stage1.loc[df_stage1[\"jump_backs\"].argmax()][\"label\"]\n",
    "    if target_label not in target_queries:\n",
    "        target_queries.append(target_label)\n",
    "\n",
    "    # determine the query with the largest difference in plan changes between minimal and full stage\n",
    "    df_stage5 = df.query(\"stage == 'parallel'\")\n",
    "    df_extremes = pd.merge(\n",
    "        df_stage1[[\"label\", \"plan_changes\"]],\n",
    "        df_stage5[[\"label\", \"plan_changes\"]],\n",
    "        on=\"label\",\n",
    "        suffixes=(\"_min\", \"_full\"),\n",
    "    )\n",
    "\n",
    "    df_extremes[\"plan_changes_diff\"] = np.abs(\n",
    "        df_extremes[\"plan_changes_full\"] - df_extremes[\"plan_changes_min\"]\n",
    "    )\n",
    "    target_label = df_extremes.loc[df_extremes[\"plan_changes_diff\"].argmax()][\"label\"]\n",
    "    if target_label not in target_queries:\n",
    "        target_queries.append(target_label)\n",
    "\n",
    "    # determine the query with the most plan changes at an intermediate stage where this number is larger than the number of\n",
    "    # plan changes at the minimal and full stages\n",
    "    df_extremes[\"extremes_changes\"] = np.maximum(\n",
    "        df_extremes[\"plan_changes_min\"], df_extremes[\"plan_changes_full\"]\n",
    "    )\n",
    "    df_inners = pd.merge(\n",
    "        df[~df[\"stage\"].isin([\"minimal\", \"parallel\"])][[\"label\", \"plan_changes\"]],\n",
    "        df_extremes[[\"label\", \"extremes_changes\"]],\n",
    "        on=\"label\",\n",
    "    )\n",
    "    df_inners = df_inners.query(\"plan_changes > extremes_changes\")\n",
    "    target_label = df_inners.loc[df_inners[\"plan_changes\"].argmax()][\"label\"]\n",
    "    target_queries.append(target_label)\n",
    "\n",
    "    return make_evolution_plot(\n",
    "        df, workload=workload, cost_model=\"cout\", export=False, queries=target_queries\n",
    "    )\n",
    "\n",
    "\n",
    "def make_summary(df: pd.DataFrame | None) -> Optional[pd.DataFrame]:\n",
    "    if df is None:\n",
    "        return None\n",
    "\n",
    "    extremes_df = (\n",
    "        df.drop(columns=[\"plot_label\", \"stage_pretty\"], errors=\"ignore\")\n",
    "        .query(\"stage == 'minimal' | stage == 'parallel'\")\n",
    "        .pivot(columns=[\"stage\"], index=[\"cost_model\", \"label\"])\n",
    "    )\n",
    "    extremes_df.columns = [\n",
    "        f\"{measure}_{stage[:3]}\"\n",
    "        for measure, stage in extremes_df.columns.to_flat_index()\n",
    "    ]\n",
    "    extremes_df.reset_index(inplace=True)\n",
    "\n",
    "    plans_min_less_full = (\n",
    "        extremes_df.query(\"plan_changes_min < plan_changes_par\")\n",
    "        .groupby(\"cost_model\", as_index=False)[\"label\"]\n",
    "        .count()\n",
    "    )\n",
    "\n",
    "    plans_min_larger_full = (\n",
    "        extremes_df.query(\"plan_changes_min > plan_changes_par\")\n",
    "        .groupby(\"cost_model\", as_index=False)[\"label\"]\n",
    "        .count()\n",
    "    )\n",
    "\n",
    "    plans_intermediate_max = (\n",
    "        df.merge(\n",
    "            df.query(\"stage == 'minimal'\")[[\"cost_model\", \"label\", \"plan_changes\"]],\n",
    "            on=[\"cost_model\", \"label\"],\n",
    "            suffixes=(\"\", \"_min\"),\n",
    "        )\n",
    "        .merge(\n",
    "            df.query(\"stage == 'parallel'\")[[\"cost_model\", \"label\", \"plan_changes\"]],\n",
    "            on=[\"cost_model\", \"label\"],\n",
    "            suffixes=(\"\", \"_full\"),\n",
    "        )\n",
    "        .query(\n",
    "            \"stage != 'minimal' & stage != 'parallel' & plan_changes > plan_changes_min & plan_changes > plan_changes_full\"\n",
    "        )\n",
    "        .groupby([\"cost_model\", \"label\"], as_index=False, observed=True)[\"plan_changes\"]\n",
    "        .agg(lambda xs: 1)\n",
    "        .groupby(\"cost_model\", as_index=False, observed=True)[\"label\"]\n",
    "        .count()\n",
    "    )\n",
    "\n",
    "    jumps_min_less_full = (\n",
    "        extremes_df.query(\"jump_backs_min > jump_backs_par\")\n",
    "        .groupby(\"cost_model\", as_index=False)[\"label\"]\n",
    "        .count()\n",
    "    )\n",
    "\n",
    "    jumps_min_larger_full = (\n",
    "        extremes_df.query(\"jump_backs_min < jump_backs_par\")\n",
    "        .groupby(\"cost_model\", as_index=False)[\"label\"]\n",
    "        .count()\n",
    "    )\n",
    "\n",
    "    jumps_intermediate_max = (\n",
    "        df.merge(\n",
    "            df.query(\"stage == 'minimal'\")[[\"cost_model\", \"label\", \"jump_backs\"]],\n",
    "            on=[\"cost_model\", \"label\"],\n",
    "            suffixes=(\"\", \"_min\"),\n",
    "        )\n",
    "        .merge(\n",
    "            df.query(\"stage == 'parallel'\")[[\"cost_model\", \"label\", \"jump_backs\"]],\n",
    "            on=[\"cost_model\", \"label\"],\n",
    "            suffixes=(\"\", \"_full\"),\n",
    "        )\n",
    "        .query(\n",
    "            \"stage != 'minimal' & stage != 'parallel' & jump_backs > jump_backs_min & jump_backs > jump_backs_full\"\n",
    "        )\n",
    "        .groupby([\"cost_model\", \"label\"], as_index=False, observed=True)[\"jump_backs\"]\n",
    "        .agg(lambda xs: 1)\n",
    "        .groupby(\"cost_model\", as_index=False, observed=True)[\"label\"]\n",
    "        .count()\n",
    "    )\n",
    "\n",
    "    summary_df = pd.concat(\n",
    "        [\n",
    "            plans_min_less_full,\n",
    "            plans_min_larger_full,\n",
    "            plans_intermediate_max,\n",
    "            jumps_min_less_full,\n",
    "            jumps_min_larger_full,\n",
    "            jumps_intermediate_max,\n",
    "        ],\n",
    "        names=[\"statistic\"],\n",
    "        keys=[\n",
    "            \"nPlans / min < full\",\n",
    "            \"nPlans / min > full\",\n",
    "            \"nPlans / intermediate = max\",\n",
    "            \"nJumps / min < full\",\n",
    "            \"nJumps / min > full\",\n",
    "            \"nJumps / intermediate = max\",\n",
    "        ],\n",
    "    )\n",
    "    summary_df.rename(columns={\"label\": \"n_queries\"}, inplace=True)\n",
    "    return summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645ace70",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = workloads.job()\n",
    "stats = workloads.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b19b3ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_df = load_results(job)\n",
    "stats_df = load_results(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b30fca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_changes = make_changes_df(job_df)\n",
    "stats_changes = make_changes_df(stats_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c59a4b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_evolution_plot(job_changes, workload=job.name, cost_model=\"cout\", export=True)\n",
    "make_evolution_plot(job_changes, workload=job.name, cost_model=\"vanilla\", export=True)\n",
    "make_evolution_plot(stats_changes, workload=stats.name, cost_model=\"cout\", export=True)\n",
    "make_evolution_plot(\n",
    "    stats_changes, workload=stats.name, cost_model=\"vanilla\", export=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b6147a",
   "metadata": {},
   "source": [
    "# Replacement plot\n",
    "\n",
    "The main takeaway from Section 4.2 is that the issue of unstable plan selection remains,\n",
    "even if the plan enumerator and the cost model are heavily simplified. The example queries shown in Figure 5 try to paint a\n",
    "representative picture of the potential plan behavior at different ablation stages.\n",
    "\n",
    "The suggested replacement plot shows the following queries for the simplified cost model:\n",
    "\n",
    "1. query with the most number of plan changes at the _minimal_ stage (only sequential scan and nested-loop join)\n",
    "2. query with the most jumps to earlier plans at the _minimal_ stage (only sequential scan and nested-loop join)\n",
    "3. query with the largest difference between plans at the _minimal_ stage (only sequential scan and nested-loop join) and\n",
    "   the _full_ stage (all operators and parallelization)\n",
    "4. query with the largest number of plan changes at an intermediate stage (i.e. neither _minimal_, nor _full_) where this\n",
    "   number also exceeds the number of plan changes  at the _minimal_ and _full_ stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a2c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_replacement_queries(job_changes, workload=job.name, export=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b24be2",
   "metadata": {},
   "source": [
    "# Aggregated statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ec104b",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_summary(job_changes)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
