{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9f7de08",
   "metadata": {},
   "source": [
    "# Experiment 07: Beyond Textbook Optimizers\n",
    "\n",
    "Process this notebook like so to generate the PDF output:\n",
    "\n",
    "```bash\n",
    "jupyter execute --inplace 05-Beyond-Textbook.ipynb\n",
    "jupyter nbconvert --to pdf --TagRemovePreprocessor.remove_cell_tags='{\"hide\"}' 05-Beyond-Textbook.ipynb\n",
    "```\n",
    "\n",
    "# Internals\n",
    "\n",
    "The cells in this section can be ignored in the PDF output. They perform the technical aspects of the data analysis.\n",
    "This mainly involves creating data shift plots and determining the best replacements for the original plots.\n",
    "\n",
    "Please take a look at the following sections to see the actual outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a849cb7",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import figure, ticker\n",
    "\n",
    "from postbound.db import postgres\n",
    "from postbound.experiments import workloads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7223b0e",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "results_base = Path(\"/ari/results/experiment-07-beyond-textbook/\")\n",
    "output_dir = Path(\"/ari/results/eval/experiment-07-beyond-textbook/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "workloads.workloads_base_dir = \"/ari/postbound/workloads\"\n",
    "plt.rcParams[\"figure.figsize\"] = (7, 5)\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42\n",
    "plt.rcParams[\"ps.fonttype\"] = 42\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbdcdc1",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "def load_pg_explain(raw_explain: str) -> Optional[postgres.PostgresExplainPlan]:\n",
    "    plan_json = json.loads(raw_explain)\n",
    "    if not plan_json:\n",
    "        return None\n",
    "    return postgres.PostgresExplainPlan(plan_json)\n",
    "\n",
    "\n",
    "def read_df(workload: workloads.Workload) -> Optional[pd.DataFrame]:\n",
    "    data_file = results_base / workload.name.lower() / \"data-shift.csv\"\n",
    "    if not data_file.exists():\n",
    "        return None\n",
    "\n",
    "    df = pd.read_csv(data_file, converters={\"query_plan\": load_pg_explain})\n",
    "    df[\"label\"] = pd.Categorical(df[\"label\"], categories=workload.labels(), ordered=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_evolution_plots(df: pd.DataFrame | None, *, workload: workloads.Workload) -> dict[str, figure.Figure]:\n",
    "    if df is None:\n",
    "        return {}\n",
    "\n",
    "    plots: dict[str, figure.Figure] = {}\n",
    "\n",
    "    for label in workload.labels():\n",
    "        current_samples = df.query(\"label == @label\").copy()\n",
    "        current_samples[\"plan_type\"] = current_samples[\"plan_type\"].map({\"native-fixed\": \"PG native\", \"robust-fixed\": \"Robust (UES)\"})\n",
    "        current_samples[\"db_size\"] = (current_samples[\"fill_ratio\"] / 0.6) * 100\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        g = sns.lineplot(current_samples, x=\"db_size\", y=\"total_runtime\",\n",
    "                        hue=\"plan_type\", style=\"plan_type\",\n",
    "                        markers=True, dashes=False, ax=ax)\n",
    "        g.axvline(100.0, color=\"grey\", linestyle=\":\")\n",
    "        g.set(xlabel=\"Database size\", ylabel=\"Runtime [s]\",\n",
    "            title=f\"{workload.name} query {label}\")\n",
    "        g.xaxis.set_major_formatter(ticker.PercentFormatter())\n",
    "        g.legend(title=\"Optimizer type\")\n",
    "\n",
    "        fig.tight_layout()\n",
    "        out_file = output_dir / workload.name.lower() / f\"data-shift-{label}.pdf\"\n",
    "        out_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        fig.savefig(out_file)\n",
    "        plt.close(fig)\n",
    "\n",
    "        plots[label] = fig\n",
    "\n",
    "    return plots\n",
    "\n",
    "\n",
    "def linear_approx(fill_ratios: pd.Series, *, min_fr, max_fr, min_rt, max_rt) -> pd.Series:\n",
    "    m = (max_rt - min_rt) / (max_fr - min_fr)\n",
    "    n = min_rt - (m * min_fr)\n",
    "    return m * fill_ratios + n\n",
    "\n",
    "def determine_largest_jump(current_sample: pd.DataFrame) -> pd.Series:\n",
    "    current_sample = current_sample.sort_values(by=\"fill_ratio\").reset_index(drop=True)\n",
    "\n",
    "    min_fill_ratio, max_fill_ratio = current_sample[\"fill_ratio\"].min(), current_sample[\"fill_ratio\"].max()\n",
    "    min_rt = current_sample.query(\"fill_ratio == @min_fill_ratio\")[\"total_runtime\"].item()\n",
    "    max_rt = current_sample.query(\"fill_ratio == @max_fill_ratio\")[\"total_runtime\"].item()\n",
    "\n",
    "    approx_rts = linear_approx(current_sample[\"fill_ratio\"], min_fr=min_fill_ratio, max_fr=max_fill_ratio, min_rt=min_rt, max_rt=max_rt)\n",
    "    rt_deviation = current_sample[\"total_runtime\"] - approx_rts\n",
    "\n",
    "    jump_point = rt_deviation.abs().idxmax()\n",
    "    expected_runtime = current_sample.at[jump_point, \"total_runtime\"]\n",
    "    actual_runtime = approx_rts.loc[jump_point]\n",
    "    jump_slowdown = max(expected_runtime, actual_runtime) / min(expected_runtime, actual_runtime)\n",
    "    jump_fill_ratio = current_sample.at[jump_point, \"fill_ratio\"]\n",
    "    return pd.Series(dict(jump_point=jump_fill_ratio, slowdown=jump_slowdown, min_rt=min_rt, max_rt=max_rt))\n",
    "\n",
    "\n",
    "def make_jumps_df(df: pd.DataFrame | None) -> Optional[pd.DataFrame]:\n",
    "    if df is None:\n",
    "        return None\n",
    "\n",
    "    jumps_df = (df\n",
    "                .groupby([\"plan_type\", \"label\"], as_index=False, observed=True)\n",
    "                .apply(determine_largest_jump, include_groups=False)\n",
    "                .assign(rt_diff=lambda samples: samples[\"max_rt\"] - samples[\"min_rt\"])\n",
    "                .sort_values(by=[\"label\", \"plan_type\"]))\n",
    "\n",
    "    return jumps_df\n",
    "\n",
    "\n",
    "def select_underest_jump_replacement(df: pd.DataFrame | None, *, workload: workloads.Workload, plots: dict[str, figure.Figure]) -> Optional[figure.Figure]:\n",
    "    if df is None:\n",
    "        return None\n",
    "\n",
    "    underest_results = df.query(\"rt_diff >= 1 & slowdown >= 1.3 & jump_point >= 0.6\")\n",
    "    if underest_results.empty:\n",
    "        warnings.warn(f\"No jumps during underestimation detected for workload {workload.name}\")\n",
    "        return None\n",
    "\n",
    "    selected: str = underest_results.iloc[underest_results[\"rt_diff\"].argmax()][\"label\"]\n",
    "    return plots[selected]\n",
    "\n",
    "\n",
    "def select_overest_jump_replacement(df: pd.DataFrame | None, *, workload: workloads.Workload, plots: dict[str, figure.Figure]) -> Optional[figure.Figure]:\n",
    "    if df is None:\n",
    "        return None\n",
    "\n",
    "    underest_results = df.query(\"rt_diff >= 1 & slowdown >= 1.3 & jump_point < 0.6\")\n",
    "    if underest_results.empty:\n",
    "        warnings.warn(f\"No jumps during overestimation detected for workload {workload.name}\")\n",
    "        return None\n",
    "\n",
    "    selected: str = underest_results.iloc[underest_results[\"rt_diff\"].argmax()][\"label\"]\n",
    "    return plots[selected]\n",
    "\n",
    "\n",
    "def make_jump_count_summary(df: pd.DataFrame | None) -> Optional[pd.DataFrame]:\n",
    "    if df is None:\n",
    "        return None\n",
    "\n",
    "    df = df.copy()\n",
    "    df[\"plan_type\"] = df[\"plan_type\"].map({\"native-fixed\": \"PG native\", \"robust-fixed\": \"Robust (UES)\"})\n",
    "    relevant_queries = df.query(\"rt_diff >= 1\").groupby(\"plan_type\", as_index=True).size()\n",
    "    jumping_queries = df.query(\"rt_diff >= 1 & slowdown >= 1.3\").groupby(\"plan_type\", as_index=True).size()\n",
    "    results = pd.DataFrame({\"relevant_queries\": relevant_queries, \"jumping_queries\": jumping_queries}, index=relevant_queries.index)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def make_jump_pos_summary(df: pd.DataFrame | None) -> Optional[np.float64]:\n",
    "    jump_pos = (df\n",
    "            .query(\"rt_diff >= 1 & slowdown >= 1.3\")\n",
    "            .assign(jump_pos=lambda sample: np.where(sample[\"jump_point\"] <= 0.6, \"overest\", \"underest\"))\n",
    "            .groupby(\"jump_pos\")\n",
    "            .size())\n",
    "    underest_share = 1 - jump_pos.loc[\"underest\"] / jump_pos.sum()\n",
    "    return underest_share\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2812df1f",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "job = workloads.job()\n",
    "stats = workloads.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a996b6a",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "df_job = read_df(job)\n",
    "df_stats = read_df(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cbd24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_plots = make_evolution_plots(df_job, workload=job)\n",
    "_ = make_evolution_plots(df_stats, workload=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1f3fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "jumps_job = make_jumps_df(df_job)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbbca0d",
   "metadata": {},
   "source": [
    "# Suggested replacement plots\n",
    "\n",
    "These are the plots that might be the best replacements for the original plots based on the current hardware. See the README\n",
    "for the motivation behind this strategy.\n",
    "\n",
    "Please note that these plots are determined automatically using a coarse heuristic. In contrast, the plots in the original\n",
    "paper have been selected semi-automatically using the same statistics but with human oversight. If one of the plots shows a\n",
    "significant difference, please take a look at the remaining plots for the other queries. Perhaps the heuristic selected a poor\n",
    "replacement plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009c2004",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_overest_jump_replacement(jumps_job, workload=job, plots=job_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a5d32b",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_underest_jump_replacement(jumps_job, workload=job, plots=job_plots)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9888010",
   "metadata": {},
   "source": [
    "# Aggregated statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678adaf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_jump_count_summary(jumps_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86dd3014",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_jump_pos_summary(jumps_job)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
