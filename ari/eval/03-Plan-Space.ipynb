{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acf4730d",
   "metadata": {},
   "source": [
    "# Experiment 03: Plan Space\n",
    "\n",
    "Process this notebook like so to generate the PDF output:\n",
    "\n",
    "```bash\n",
    "jupyter execute --inplace 03-Plan-Space.ipynb\n",
    "jupyter nbconvert --to pdf 03-Plan-Space.ipynb\n",
    "```\n",
    "\n",
    "# Internals\n",
    "\n",
    "The cells in this section can be ignored in the PDF output. They perform the technical aspects of the data analysis.\n",
    "This mainly involves creating distortion plots (Figure 3 in the original paper) and determining the best replacements for\n",
    "the original plots.\n",
    "\n",
    "Please take a look at the following sections to see the actual outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61cb0540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections.abc import Iterable\n",
    "from pathlib import Path\n",
    "from typing import Literal, Optional\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats\n",
    "import seaborn as sns\n",
    "from matplotlib import figure\n",
    "\n",
    "from postbound.db import db, postgres\n",
    "from postbound.experiments import workloads\n",
    "from postbound.optimizer import jointree\n",
    "from postbound.optimizer.policies import cardinalities\n",
    "from postbound.qal import qal\n",
    "from postbound.util import collections as collection_utils\n",
    "from postbound.util import jsonize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434a9804",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_base = Path(\"/ari/results/experiment-03-plan-space-analysis/\")\n",
    "imperfect_results_base = Path(\"/ari/results/experiment-04-base-join-impact/\")\n",
    "output_dir = Path(\"/ari/results/eval/experiment-03-plan-space/\")\n",
    "imperfect_out_dir = Path(\"/ari/results/eval/experiment-04-base-join-impact/\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "imperfect_out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "static_results_base = Path(\"/ari/results/00-base\")\n",
    "workloads.workloads_base_dir = \"/ari/postbound/workloads\"\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 5)\n",
    "plt.rcParams[\"pdf.fonttype\"] = 42\n",
    "plt.rcParams[\"ps.fonttype\"] = 42\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d1d133",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pg_explain(raw_explain: str) -> Optional[postgres.PostgresExplainPlan]:\n",
    "    plan_json = json.loads(raw_explain)\n",
    "    if not plan_json:\n",
    "        return None\n",
    "    return postgres.PostgresExplainPlan(plan_json)\n",
    "\n",
    "\n",
    "def load_results(workload: workloads.Workload) -> Optional[pd.DataFrame]:\n",
    "    result_df = pd.DataFrame()\n",
    "    workload_name = workload.name.lower()\n",
    "\n",
    "    for label in workload.labels():\n",
    "        data_file = results_base / workload_name / f\"plan-space-analysis-{label}.csv\"\n",
    "        if not data_file.exists():\n",
    "            continue\n",
    "\n",
    "        current_df = pd.read_csv(data_file, converters={\"query_plan\": load_pg_explain})\n",
    "        current_df[\"estimated_cost\"] = current_df[\"query_plan\"].map(\n",
    "            lambda plan: plan.explain_data[\"Plan\"][\"Total Cost\"]\n",
    "        )\n",
    "        current_df[\"plan_hash\"] = current_df[\"query_plan\"].map(hash)\n",
    "\n",
    "        result_df = pd.concat([result_df, current_df], ignore_index=True)\n",
    "\n",
    "    if result_df.empty:\n",
    "        return None\n",
    "\n",
    "    result_df[\"label\"] = pd.Categorical(\n",
    "        result_df[\"label\"], categories=workload.labels(), ordered=True\n",
    "    )\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def prediction_error(samples: pd.DataFrame) -> pd.Series:\n",
    "    fit = scipy.stats.linregress(samples[\"estimated_cost\"], samples[\"runtime\"])\n",
    "    prediction = fit.slope * samples[\"estimated_cost\"] + fit.intercept\n",
    "    error = np.abs(samples[\"runtime\"] - prediction) / samples[\"runtime\"]\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        {\"predicted_runtime\": prediction, \"prediction_error\": error},\n",
    "        index=samples.index,\n",
    "    )\n",
    "\n",
    "\n",
    "def make_correlation_plots(\n",
    "    df: pd.DataFrame | None, *, workload: workloads.Workload\n",
    ") -> None:\n",
    "    if df is None:\n",
    "        return\n",
    "\n",
    "    for label in workload.labels():\n",
    "        samples = df.query(\"label == @label and ~timeout\")\n",
    "        corr_value = round(\n",
    "            scipy.stats.pearsonr(\n",
    "                samples[\"estimated_cost\"], samples[\"runtime\"]\n",
    "            ).statistic,\n",
    "            2,\n",
    "        )\n",
    "        title = f\"{workload.name} query {label} [Pearson-r = {corr_value}]\"\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        g = sns.regplot(\n",
    "            samples,\n",
    "            x=\"estimated_cost\",\n",
    "            y=\"runtime\",\n",
    "            scatter=True,\n",
    "            scatter_kws={\"edgecolors\": \"white\"},\n",
    "            ax=ax,\n",
    "        )\n",
    "        g.set_xscale(\"log\", subs=[])\n",
    "        g.set(xlabel=\"Estimated cost [log]\", ylabel=\"Execution time [s]\", title=title)\n",
    "\n",
    "        out_file = output_dir / workload.name.lower() / f\"cost-runtime-corr-{label}.pdf\"\n",
    "        out_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        fig.tight_layout()\n",
    "        fig.savefig(out_file)\n",
    "        plt.close(fig)\n",
    "\n",
    "\n",
    "def prediction_error_df(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    err_df = (\n",
    "        df.query(\"~timeout\")\n",
    "        .groupby(\"label\", as_index=False, observed=True)\n",
    "        .apply(prediction_error, include_groups=False)\n",
    "        .reset_index(level=1)\n",
    "    )\n",
    "\n",
    "    return df.merge(err_df, left_index=True, right_on=\"level_1\").drop(columns=\"level_1\")\n",
    "\n",
    "\n",
    "def lookup_base_joins(\n",
    "    qep: db.QueryExecutionPlan | postgres.PostgresExplainPlan,\n",
    ") -> set[db.QueryExecutionPlan]:\n",
    "    qep = (\n",
    "        qep if isinstance(qep, db.QueryExecutionPlan) else qep.as_query_execution_plan()\n",
    "    )\n",
    "    return (\n",
    "        {qep}\n",
    "        if qep.is_base_join()\n",
    "        else collection_utils.set_union(\n",
    "            lookup_base_joins(child) for child in qep.children\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "def make_base_join_df(df: pd.DataFrame | None) -> Optional[pd.DataFrame]:\n",
    "    if df is None:\n",
    "        return None\n",
    "\n",
    "    df[\"base_join\"] = (\n",
    "        df[\"query_plan\"]\n",
    "        .map(lookup_base_joins)\n",
    "        .map(lambda joins: {frozenset(join.tables()) for join in joins})\n",
    "    )\n",
    "    df = df.explode(\"base_join\")\n",
    "    df[\"join_label\"] = df[\"base_join\"].map(\n",
    "        lambda join: \" â‹ˆ \".join(tab.identifier() for tab in sorted(join))\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def make_base_join_plots(\n",
    "    df: pd.DataFrame | None, *, workload: workloads.Workload\n",
    ") -> dict[str, figure.Figure]:\n",
    "    if df is None:\n",
    "        return {}\n",
    "\n",
    "    plots: dict[str, figure.Figure] = {}\n",
    "    for label in workload.labels():\n",
    "        samples = df.query(\"label == @label\").sort_values(by=\"join_label\")\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        g = sns.scatterplot(samples, x=\"runtime\", y=\"join_label\", ax=ax)\n",
    "        g.set(\n",
    "            xlabel=\"Plan runtime [s]\",\n",
    "            ylabel=\"Base join\",\n",
    "            title=f\"{workload.name} query {label}\",\n",
    "        )\n",
    "\n",
    "        out_file = output_dir / workload.name.lower() / f\"base-joins-{label}.pdf\"\n",
    "        out_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "        fig.tight_layout()\n",
    "\n",
    "        plots[label] = fig\n",
    "        fig.savefig(out_file)\n",
    "        plt.close(fig)\n",
    "\n",
    "    return plots\n",
    "\n",
    "\n",
    "def make_importance_dfs(\n",
    "    plan_df: pd.DataFrame | None, base_join_df: pd.DataFrame\n",
    ") -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "    if plan_df is None:\n",
    "        return None, None\n",
    "\n",
    "    # First, compute the minimum/maximum runtimes and the top 25% threshold for each query\n",
    "    rt_summary = (\n",
    "        plan_df.groupby(  # don't use base_join_df here, it contains duplicates which skew the quantile!\n",
    "            \"label\", as_index=False, observed=False\n",
    "        )\n",
    "        .agg(\n",
    "            min_rt=pd.NamedAgg(column=\"runtime\", aggfunc=\"min\"),\n",
    "            max_rt=pd.NamedAgg(column=\"runtime\", aggfunc=lambda rts: rts.quantile(0.9)),\n",
    "        )\n",
    "        .assign(\n",
    "            top25_rt=lambda sample: 0.75 * sample[\"min_rt\"] + 0.25 * sample[\"max_rt\"]\n",
    "        )\n",
    "    )  # unrolled form: min + 0.25 * (max - min)\n",
    "\n",
    "    # Now, determine how many of the execution plans are in the top 25% for each query\n",
    "    top25_plans = (\n",
    "        plan_df.merge(  # see comment above: never use base_join_df here\n",
    "            rt_summary, on=\"label\"\n",
    "        )\n",
    "        .query(\"runtime <= top25_rt\")\n",
    "        .groupby(\n",
    "            [\"label\", \"top25_rt\"], as_index=False, observed=True\n",
    "        )  # top25_rt is dependent, we just carry it along\n",
    "        .size()\n",
    "        .rename(columns={\"size\": \"total_top25_plans\"})\n",
    "    )\n",
    "\n",
    "    # We are ready to compute the F1 score for each base join\n",
    "    join_importance_df = (\n",
    "        base_join_df.merge(top25_plans, on=\"label\")\n",
    "        .assign(top25_indicator=lambda sample: sample[\"runtime\"] <= sample[\"top25_rt\"])\n",
    "        .groupby(\n",
    "            [\"label\", \"base_join\", \"join_label\", \"total_top25_plans\"],\n",
    "            as_index=False,\n",
    "            observed=True,\n",
    "        )  # total_top25_plans is dependent, we just carry it along\n",
    "        .agg(\n",
    "            base_join_plans=pd.NamedAgg(\n",
    "                column=\"plan_hash\", aggfunc=\"nunique\"\n",
    "            ),  # how many plans do we have for this base join? (Theoretically, we don't need to do nunique here since the plans should be unique anyway, but its more expressive..)\n",
    "            top25_plans=pd.NamedAgg(column=\"top25_indicator\", aggfunc=\"sum\"),\n",
    "        )  # how many of these plans are in the top 25%?\n",
    "        .assign(\n",
    "            precision=lambda sample: sample[\"top25_plans\"] / sample[\"base_join_plans\"],\n",
    "            recall=lambda sample: sample[\"top25_plans\"] / sample[\"total_top25_plans\"],\n",
    "            f1_score=lambda sample: 2\n",
    "            * sample[\"precision\"]\n",
    "            * sample[\"recall\"]\n",
    "            / (sample[\"precision\"] + sample[\"recall\"]),\n",
    "        )\n",
    "        .sort_values(by=[\"label\", \"join_label\"])\n",
    "    )\n",
    "\n",
    "    # Prepare for the aggregated F1 scores: determine the weighting factor for each base join\n",
    "    importance_weigths = (\n",
    "        join_importance_df.sort_values(by=\"f1_score\", ascending=False)\n",
    "        .groupby(\"label\", as_index=False, observed=True)[\"join_label\"]\n",
    "        .transform(lambda sample: np.arange(len(sample)) + 1)\n",
    "        .to_frame()\n",
    "        .rename(columns={\"join_label\": \"harmonic_weight\"})\n",
    "    )\n",
    "\n",
    "    # Also, we will need to know which base join was actually the best for each query, so let's just compute this here as well\n",
    "    max_f1s = (\n",
    "        join_importance_df.assign(\n",
    "            max_f1=(\n",
    "                join_importance_df.groupby(\"label\", observed=True)[\n",
    "                    \"f1_score\"\n",
    "                ].transform(\"max\")\n",
    "            )\n",
    "        )\n",
    "        .query(\"f1_score == max_f1\")\n",
    "        .rename(columns={\"base_join\": \"best_join\"})[[\"label\", \"best_join\"]]\n",
    "    )\n",
    "\n",
    "    # Finally, all that's left to do is aggregate\n",
    "    harmonic_importance = (\n",
    "        join_importance_df.merge(importance_weigths, left_index=True, right_index=True)\n",
    "        .merge(max_f1s, on=\"label\")\n",
    "        .assign(\n",
    "            f1_harmonic=lambda sample: 1\n",
    "            / sample[\"harmonic_weight\"]\n",
    "            * sample[\"f1_score\"]\n",
    "        )\n",
    "        .groupby([\"label\", \"best_join\"], as_index=False, observed=True)\n",
    "        .agg(f1_harmonic=pd.NamedAgg(column=\"f1_harmonic\", aggfunc=\"sum\"))\n",
    "    )\n",
    "\n",
    "    return join_importance_df, harmonic_importance\n",
    "\n",
    "\n",
    "def select_important_base_join_replacement(\n",
    "    importance_df: pd.DataFrame | None, *, plots: dict[str, figure.Figure]\n",
    ") -> Optional[figure.Figure]:\n",
    "    if importance_df is None:\n",
    "        return None\n",
    "    selected: str = importance_df.iloc[importance_df[\"f1_harmonic\"].argmax()][\"label\"]\n",
    "    return plots[selected]\n",
    "\n",
    "\n",
    "def select_whatever_base_join_replacement(\n",
    "    importance_df: pd.DataFrame | None, *, plots: dict[str, figure.Figure]\n",
    ") -> Optional[figure.Figure]:\n",
    "    if importance_df is None:\n",
    "        return None\n",
    "    selected: str = importance_df.iloc[importance_df[\"f1_harmonic\"].argmin()][\"label\"]\n",
    "    return plots[selected]\n",
    "\n",
    "\n",
    "def make_join_importance_plot(\n",
    "    importance_df: pd.DataFrame | None,\n",
    "    *,\n",
    "    workload: workloads.Workload,\n",
    "    thresh: float = 0.75,\n",
    ") -> Optional[figure.Figure]:\n",
    "    if importance_df is None:\n",
    "        return None\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    g = sns.barplot(\n",
    "        importance_df.assign(relevant=importance_df[\"f1_harmonic\"] >= thresh),\n",
    "        x=\"label\",\n",
    "        y=\"f1_harmonic\",\n",
    "        hue=\"relevant\",\n",
    "        hue_order=[True, False],\n",
    "        ax=ax,\n",
    "    )\n",
    "    g.xaxis.set_ticks(workload.labels())\n",
    "    g.axhline(thresh, color=\"grey\", linestyle=\"dashed\")\n",
    "    g.set_xticklabels(\n",
    "        [\n",
    "            label\n",
    "            if label.get_text()[-1] == \"a\"\n",
    "            and ((int(label.get_text()[:-1]) % 5 == 0) or (i == 0))\n",
    "            else \"\"\n",
    "            for i, label in enumerate(g.get_xticklabels())\n",
    "        ]\n",
    "    )\n",
    "    g.set(xlabel=\"Query\", ylabel=\"Importance score\")\n",
    "    g.legend().remove()\n",
    "    fig.tight_layout()\n",
    "\n",
    "    out_file = output_dir / workload.name.lower() / \"base-join-importance.pdf\"\n",
    "    out_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    fig.savefig(out_file)\n",
    "    plt.close(fig)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "def load_jointree(\n",
    "    query_plan: postgres.PostgresExplainPlan, *, query: qal.SqlQuery\n",
    ") -> jointree.LogicalJoinTree:\n",
    "    qep = query_plan.as_query_execution_plan()\n",
    "    return jointree.LogicalJoinTree.load_from_query_plan(qep, query=query)\n",
    "\n",
    "\n",
    "def load_imperfect_results(workload: workloads.Workload) -> Optional[pd.DataFrame]:\n",
    "    result_df = pd.DataFrame()\n",
    "\n",
    "    for label, query in workload.entries():\n",
    "        data_file = (\n",
    "            imperfect_results_base\n",
    "            / workload.name.lower()\n",
    "            / f\"base-tab-operator-flexibility-{label}.csv\"\n",
    "        )\n",
    "        if not data_file.exists():\n",
    "            continue\n",
    "\n",
    "        current_df = pd.read_csv(data_file, converters={\"query_plan\": load_pg_explain})\n",
    "        current_df[\"join_order\"] = current_df[\"query_plan\"].apply(\n",
    "            load_jointree, query=query\n",
    "        )\n",
    "\n",
    "        result_df = pd.concat([result_df, current_df], ignore_index=True)\n",
    "\n",
    "    if result_df.empty:\n",
    "        return None\n",
    "\n",
    "    result_df[\"label\"] = pd.Categorical(\n",
    "        result_df[\"label\"], categories=workload.labels(), ordered=True\n",
    "    )\n",
    "\n",
    "    return result_df\n",
    "\n",
    "\n",
    "def make_native_est_impact_df(\n",
    "    importance_df: pd.DataFrame | None, *, workload: workloads.Workload\n",
    ") -> Optional[pd.DataFrame]:\n",
    "    if importance_df is None:\n",
    "        return None\n",
    "\n",
    "    imperfect_df = load_imperfect_results(workload)\n",
    "    important_labels = set(imperfect_df[\"label\"])\n",
    "\n",
    "    perfect_samples = importance_df[\n",
    "        importance_df[\"label\"].isin(important_labels)\n",
    "    ].copy()\n",
    "    perfect_samples[\"join_order\"] = perfect_samples.apply(\n",
    "        lambda sample: load_jointree(\n",
    "            sample[\"query_plan\"], query=workload[sample[\"label\"]]\n",
    "        ),\n",
    "        axis=\"columns\",\n",
    "    )\n",
    "\n",
    "    native_est_impact = pd.DataFrame()\n",
    "    for label in important_labels:\n",
    "        perfect_cards = perfect_samples.query(\"label == @label\")\n",
    "        imperfect_cards = imperfect_df.query(\"label == @label\")\n",
    "\n",
    "        current_impact_df = pd.merge(\n",
    "            perfect_cards[[\"label\", \"runtime\", \"join_order\"]],\n",
    "            imperfect_cards[[\"label\", \"runtime\", \"join_order\"]],\n",
    "            on=[\"label\", \"join_order\"],\n",
    "            suffixes=(\"_perf\", \"_nat\"),\n",
    "        )\n",
    "        native_est_impact = pd.concat(\n",
    "            [native_est_impact, current_impact_df], ignore_index=True\n",
    "        )\n",
    "\n",
    "    native_est_impact.sort_values(by=\"label\", inplace=True)\n",
    "    return native_est_impact\n",
    "\n",
    "\n",
    "def make_card_impact_plot(\n",
    "    card_impact_df: pd.DataFrame | None, *, workload: workloads.Workload\n",
    ") -> Optional[figure.Figure]:\n",
    "    if card_impact_df is None:\n",
    "        return None\n",
    "\n",
    "    min_rt = card_impact_df[[\"runtime_nat\", \"runtime_perf\"]].min().min()\n",
    "    max_rt = card_impact_df[[\"runtime_nat\", \"runtime_perf\"]].max().max()\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ticks = [0.1, 0.5, 1.0, 2.5, 5.0, 10]\n",
    "\n",
    "    g = sns.scatterplot(card_impact_df, x=\"runtime_perf\", y=\"runtime_nat\", ax=ax)\n",
    "    g.plot([min_rt, max_rt], [min_rt, max_rt], color=\"grey\", linestyle=\"dashed\")\n",
    "    g.set_xscale(\"log\")\n",
    "    g.set_yscale(\"log\")\n",
    "    g.xaxis.set_ticks(ticks, labels=ticks)\n",
    "    g.yaxis.set_ticks(ticks, labels=ticks)\n",
    "    g.set(xlabel=\"Estimated card. runtime [s]\", ylabel=\"Perfect card. runtime [s]\")\n",
    "\n",
    "    out_file = (\n",
    "        imperfect_out_dir / workload.name.lower() / \"base-join-imperfect-slowdown.pdf\"\n",
    "    )\n",
    "    out_file.parent.mkdir(parents=True, exist_ok=True)\n",
    "    fig.tight_layout()\n",
    "    fig.savefig(out_file)\n",
    "    plt.close(fig)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11285af",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = workloads.job()\n",
    "stats = workloads.stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cca6134",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_job = load_results(job)\n",
    "df_stats = load_results(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c8e0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_joins_job = make_base_join_df(df_job)\n",
    "base_joins_stats = make_base_join_df(df_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "672d414c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_join_plots_job = make_base_join_plots(base_joins_job, workload=job)\n",
    "_ = make_base_join_plots(base_joins_stats, workload=stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451c0428",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_importance_job, harmonic_importance_job = make_importance_dfs(\n",
    "    df_job, base_joins_job\n",
    ")\n",
    "join_importance_stats, harmonic_importance_stats = make_importance_dfs(\n",
    "    df_stats, base_joins_stats\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a83dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "imperfect_df_job = load_imperfect_results(job)\n",
    "imperfect_df_stats = load_imperfect_results(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9aaf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "native_est_impact_job = make_native_est_impact_df(join_importance_job, workload=job)\n",
    "native_est_impact_stats = make_native_est_impact_df(\n",
    "    join_importance_stats, workload=stats\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ae304f",
   "metadata": {},
   "source": [
    "# Section 5.1 - cost / runtime correlation\n",
    "\n",
    "(Mean, median) prediction error on JOB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca18111",
   "metadata": {},
   "outputs": [],
   "source": [
    "errs_job = prediction_error_df(df_job)[\"prediction_error\"]\n",
    "errs_job.mean(), errs_job.median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e3d4d5",
   "metadata": {},
   "source": [
    "# Section 5.2 - impact of base joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39dc90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_important_base_join_replacement(\n",
    "    harmonic_importance_job, plots=base_join_plots_job\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0f40cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_whatever_base_join_replacement(\n",
    "    harmonic_importance_job, plots=base_join_plots_job\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4f802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "join_importance_plot = make_join_importance_plot(harmonic_importance_job, workload=job)\n",
    "_ = make_join_importance_plot(harmonic_importance_stats, workload=stats)\n",
    "\n",
    "join_importance_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e031871",
   "metadata": {},
   "source": [
    "# Section 5.2 - impact of imperfect estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25249c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "card_impact_plot = make_card_impact_plot(native_est_impact_job, workload=job)\n",
    "_ = make_card_impact_plot(native_est_impact_stats, workload=stats)\n",
    "\n",
    "card_impact_plot"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
